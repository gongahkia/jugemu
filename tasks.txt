Add ingestion metadata in Chroma: source file, line number, timestamp (if known), speaker (if known)
Add robust dedupe strategy: stable IDs + optional fuzzy dedupe for near-identical messages
Add a `VectorStore` interface with two backends: Chroma (local) and Cassandra/Astra (remote)
Implement Cassandra/Astra backend using DataStax clients, including schema/table creation and vector similarity queries
Add backend selection flag: `--vector-backend chroma|cassandra` and shared config loading
Document Chroma behavior that duplicate IDs are ignored and make ingestion idempotent by design (aligns with Chroma docs)
Add a config file (`config.toml`) to avoid long CLI flags and keep runs reproducible
Add a single "train+ingest" pipeline command that runs: parse -> ingest -> train -> smoke-sample (one command, still tiny)
Add `make`/`just` shortcuts for practitioners: `make ingest`, `make train`, `make chat`
Add packaging: `pip install -e .` support and console scripts entrypoints for `jugemu-ingest`, `jugemu-train`, `jugemu-chat`
Add performance knobs: embedding batch size, max corpus size, optional smaller embedding model for speed
Add a migration strategy for vector store schema changes (version metadata + rebuild command)
Add a data export tool: dump random retrieved examples and their similarity scores for debugging
Add a `--dry-run` mode for ingestion that shows counts, dedupe rate, and example messages without writing DB
Add a `--browse` command that prints top-N most frequent characters/tokens to help pick model size/seq_len